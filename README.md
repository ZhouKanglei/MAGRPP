<div align="center">
  <div>
    <h1>
        MAGR++: Adaptive Manifold-Aligned Graph Regularization for Continual Action Quality Assessment
    </h1>
  </div>

  <div>
    <strong>Kanglei Zhou</strong>,  
    <a href="https://scholar.google.com/citations?user=MeNSCpQAAAAJ"><strong>Qingyi Pan</strong></a>,  
    <a href="https://indussky8.github.io/"><strong>Xingxing Zhang</strong></a>,  
    <a href="http://hubertshum.com/"><strong>Hubert P. H. Shum</strong></a>,  
    <a href="https://frederickli.webspace.durham.ac.uk/"><strong>Frederick W. B. Li</strong></a>,  
    <a href="https://orcid.org/0000-0001-6351-2538"><strong>Xiaohui Liang</strong></a>,  
    and <a href="https://lywang3081.github.io/"><strong>Liyuan Wang</strong></a>*
  </div>

  <br/>
  <div>
    Extended Version of <a href='https://github.com/ZhouKanglei/MAGR_CAQA'>MAGR (ECCV 2024 Oral Presentation)</a>
  </div>
  <br/>
</div>

---

This repository contains the implementation of **MAGR++ (`magrpp`)**, an advanced framework for **Continual Action Quality Assessment (CAQA)**.  
MAGR++ extends MAGR by integrating **layer-adaptive fine-tuning** and **asynchronous feature rectification**, effectively addressing the stabilityâ€“adaptability dilemma in continual learning.  The model combines **Manifold Projector (MP)** and **Intraâ€“Interâ€“Joint Graph Regularization (IIJ-GR)** to mitigate feature drift and regressor confusion while maintaining storage efficiency through **feature replay**.

![](framework.png)

---

## ğŸ”§ Requirements

- torch==1.12.0  
- torchvision==0.13.0  
- torchvideotransforms  
- tqdm  
- numpy  
- scipy  
- quadprog  

Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Dataset Preparation

### MTL-AQA

Download from [MTL-AQA repository](https://github.com/ParitoshParmar/MTL-AQA).

```bash
$DATASET_ROOT
â”œâ”€â”€ MTL-AQA/
â”‚   â”œâ”€â”€ new/
â”‚   â”‚   â”œâ”€â”€ 01 ...
â”‚   â”œâ”€â”€ info/
â”‚   â”‚   â”œâ”€â”€ final_annotations_dict_with_dive_number
â”‚   â”‚   â”œâ”€â”€ test_split_0.pkl
â”‚   â”‚   â””â”€â”€ train_split_0.pkl
â”‚   â””â”€â”€ model_rgb.pth
```

### UNLV-Dive (AQA-7)

```bash
mkdir AQA-Seven && cd AQA-Seven
wget http://rtis.oit.unlv.edu/datasets/AQA-7.zip
unzip AQA-7.zip
```

Organize as:

```bash
$DATASET_ROOT
â””â”€â”€ Seven/
    â”œâ”€â”€ diving-out/
    â”œâ”€â”€ gym_vault-out/
    â””â”€â”€ Split_4/
        â”œâ”€â”€ split_4_test_list.mat
        â””â”€â”€ split_4_train_list.mat
```

### UNLV-Vault

```bash
$DATASET_ROOT
â””â”€â”€ UNLV-Vault/
    â”œâ”€â”€ vault-out/
    â”‚   â”œâ”€â”€ 001/
    â”‚   â”‚   â”œâ”€â”€ img_00001.jpg
    â”‚   â”‚   â”œâ”€â”€ img_00002.jpg
    â”‚   â”‚   ...
    â”‚   â””â”€â”€ 176/
    â””â”€â”€ splits/
        â”œâ”€â”€ train_split.mat
        â”œâ”€â”€ test_split.mat
        â””â”€â”€ annotations.json
```

UNLV-Vault contains 176 vault videos and is used as the â€œvaultâ€ category in AQA-7. Each video is sampled to 103 frames, following the preprocessing settings of FineDiving.  
This dataset is used to verify the cross-domain generalization capability of MAGR++ beyond diving.

---

## ğŸ§  Pretrained Model

Download [the I3D pretrained model](https://github.com/hassony2/kinetics_i3d_pytorch/tree/master/model) 
and place it in:

```bash
weights/model_rgb.pth
```

---

## ğŸš€ Training

MAGR++ supports both **distributed** and **dataparallel** training.

### Distributed

```bash
torchrun \
  --nproc_per_node 2 --master_port 29505 main.py \
  --config ./configs/{config}.yaml \
  --model magrpp \
  --dataset {class-mtl | class-aqa | class-jdm} \
  --batch_size 5 --minibatch_size 3 --n_tasks 5 --n_epochs 50 \
  --fewshot True --buffer_size 50 \
  --gpus 0 1
```

### DataParallel

```bash
python main.py \
  --config ./configs/{config}.yaml \
  --model magrpp \
  --dataset {class-mtl | class-aqa | class-jdm} \
  --batch_size 5 --minibatch_size 3 --n_tasks 5 --n_epochs 50 \
  --fewshot True --buffer_size 50 \
  --gpus 0 1
```

---

## ğŸ§© Evaluation

To test a pretrained model:

```bash
torchrun \
  --nproc_per_node 2 --master_port 29503 main.py \
  --config ./configs/mtl.yaml \
  --model magrpp --dataset class-mtl \
  --batch_size 5 --minibatch_size 3 \
  --n_tasks 5 --n_epochs 50 --gpus 2 3 \
  --base_pretrain True --fewshot True \
  --buffer_size 50 --phase test \
  --exp_name magrpp-buffer50
```

Results and logs are saved under:

```swift
outputs/{user}/{dataset}/{exp_name}/logs
```

---

## ğŸ§­ Key Highlights of MAGR++

-   **Layer-Adaptive Fine-Tuning:**  
    Balances stability and adaptability by freezing shallow layers and fully tuning deeper ones adaptively.
    
-   **Asynchronous Feature Rectification:**  
    Decouples rectification from training to avoid premature noise accumulation.
    
-   **Manifold Projector (MP):**  
    Learns residual manifold shifts with lightweight MLPs for feature replay alignment.
    
-   **Intraâ€“Interâ€“Joint Graph Regularization (IIJ-GR):**  
    Aligns structural relations in feature and score spaces for stable regression.
    

---

## ğŸ§‘â€ğŸ’» Acknowledgements

This repository builds upon [MAGR (ECCV 2024 Oral)](https://github.com/ZhouKanglei/MAGR_CAQA) and the continual learning framework [mammoth](https://github.com/aimagelab/mammoth).  
We thank the authors for their contributions to the research community.

---

## ğŸ“¬ Contact

If you encounter issues or wish to discuss collaborations, please contact **Kanglei Zhou** or **Liyuan Wang**.



